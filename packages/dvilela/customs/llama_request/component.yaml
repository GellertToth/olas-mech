name: llama_request
author: dvilela
version: 0.1.0
type: custom
description: A tool to run local inference through llama-cpp.
license: Apache-2.0
aea_version: '>=1.0.0, <2.0.0'
fingerprint:
  __init__.py: bafybeiger6zvjsg356hyirgjadryvqlvz22wdkzqjsivkeqe3jvr33gcde
  llama_request.py: bafybeie26qv3vo3yv4fpfalpaluoyexatxtn2p5is57jhsxpkmf2fhftaa
fingerprint_ignore_patterns: []
entry_point: llama_request.py
callable: run
dependencies:
  llama-cpp-python:
    version: ==0.2.56
